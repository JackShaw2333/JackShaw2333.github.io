<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="Introduction学校人工智能实训课的笔记。 以天数为主章节，记录一下每天学习的内容，同时作复习之用。">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能实训笔记">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;09&#x2F;07&#x2F;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%AE%AD%E7%AC%94%E8%AE%B0&#x2F;index.html">
<meta property="og:site_name" content="xBug">
<meta property="og:description" content="Introduction学校人工智能实训课的笔记。 以天数为主章节，记录一下每天学习的内容，同时作复习之用。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-09-13T07:11:57.719Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/09/07/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%AE%AD%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>人工智能实训笔记 | xBug</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">xBug</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/07/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E8%AE%AD%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jared Shaw">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xBug">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能实训笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-07 20:30:58" itemprop="dateCreated datePublished" datetime="2020-09-07T20:30:58+08:00">2020-09-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-13 15:11:57" itemprop="dateModified" datetime="2020-09-13T15:11:57+08:00">2020-09-13</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>学校人工智能实训课的笔记。</p>
<p>以天数为主章节，记录一下每天学习的内容，同时作复习之用。</p>
<a id="more"></a>
<h1 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h1><h2 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h2><p>numpy是python语言中做科学计算的基础库。重在数值计算，也是大部分python科学计算库的基础，多用于在大型、多维数组上执行的数值计算。</p>
<p>可以将numpy看作一个容器，用以储存<strong>数值型</strong>数据，并且可以对数值型的数据进行很多不同形式的操作和运算。简单地来看，可以将numpy视为一个多维数组的一种高级表示。</p>
<h3 id="numpy数组和列表的区别"><a href="#numpy数组和列表的区别" class="headerlink" title="numpy数组和列表的区别"></a>numpy数组和列表的区别</h3><ul>
<li>numpy数组中只能存放相同类型的数组元素</li>
<li>numpy数组数据类型的优先级：str &gt; float &gt; int</li>
</ul>
<h3 id="numpy数组常见的创建方式"><a href="#numpy数组常见的创建方式" class="headerlink" title="numpy数组常见的创建方式"></a>numpy数组常见的创建方式</h3><ul>
<li><code>np.array()</code></li>
<li><code>np.linspace()</code></li>
<li><code>np.random.xx()</code></li>
<li><code>plt.imread()</code>。这种方式将一个图片转化为numpy数组</li>
</ul>
<h3 id="numpy的常用属性"><a href="#numpy的常用属性" class="headerlink" title="numpy的常用属性"></a>numpy的常用属性</h3><ul>
<li><code>arr.shape</code>。返回数组的形状</li>
<li><code>arr.ndim</code>。返回数组的维度</li>
<li><code>arr.size</code>。返回的数组的元素个数</li>
<li><code>arr.dtype</code>。返回数组元素的数据类型 </li>
</ul>
<h3 id="数组的索引和切片方式"><a href="#数组的索引和切片方式" class="headerlink" title="数组的索引和切片方式"></a>数组的索引和切片方式</h3><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><ul>
<li><code>arr[index]</code>。取行</li>
<li><code>arr[index, col]</code>。取元素</li>
</ul>
<h4 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h4><ul>
<li><code>arr[index1 : index2]</code>。切行</li>
<li><code>arr[:, col1 : col2]</code>。切列</li>
<li><code>arr[: : -1]</code>。行倒置</li>
<li><code>arr[:, : : -1]</code>。列倒置</li>
</ul>
<h3 id="变形"><a href="#变形" class="headerlink" title="变形"></a>变形</h3><p><code>arr.reshape()</code></p>
<p>可以将不同维度的数组变形成其他维度的数组。</p>
<p>注意：变形前和变形后的数组容量要保持一致</p>
<h3 id="级联"><a href="#级联" class="headerlink" title="级联"></a>级联</h3><p><code>arr.concatenate((arr, arr), axis = 0 or 1)</code></p>
<p>可以将多个数组进行横向或纵向的拼接</p>
<ul>
<li>axis = 0，列向拼接</li>
<li>axis = 1，航向拼接</li>
</ul>
<h3 id="一些常用的数值方法"><a href="#一些常用的数值方法" class="headerlink" title="一些常用的数值方法"></a>一些常用的数值方法</h3><ul>
<li><code>arr.mean()</code></li>
<li><code>arr.max()</code></li>
<li><code>arr.sum()</code></li>
<li><code>arr.median()</code></li>
<li><code>arr.std()</code></li>
<li><code>arr.var()</code></li>
</ul>
<h3 id="基于矩阵"><a href="#基于矩阵" class="headerlink" title="基于矩阵"></a>基于矩阵</h3><p><code>arr.T</code>。矩阵转置</p>
<h2 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h2><p>与numpy的区别在于pandas主要用来存储和运算非数值型的数据。</p>
<h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h3><p><code>Series</code>是一个类似于一维的数据结构（容器），由以下2部分组成：</p>
<ul>
<li><code>values</code>：一组数据</li>
<li><code>index</code>：相关的数据索引标签</li>
</ul>
<h3 id="创建方法"><a href="#创建方法" class="headerlink" title="创建方法"></a>创建方法</h3><ul>
<li>由列表或numpy数组创建</li>
<li>由字典创建<ul>
<li>字典所有的key组成Series的index，所有的value组成values。</li>
</ul>
</li>
</ul>
<h4 id="重要方法"><a href="#重要方法" class="headerlink" title="重要方法"></a>重要方法</h4><ul>
<li><code>s.isnull(), s.notnull()</code>。用来判断元素值是否为空。</li>
<li><code>s.unique()</code>。对Series的元素进行去重。</li>
<li><code>s.nunique()</code>。统计去重之后的元素个数。</li>
</ul>
<p>可以通过<code>bool</code>数据索引Series的值。例如，可以使用<code>s[s.notnull()]</code>选出s中不为空元素。</p>
<h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><p><code>DataFrame</code>是一个表格型的数据结构，每一行/列都是可以切成一个<code>Series</code></p>
<h4 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h4><ul>
<li><code>DataFrame(value = , index = )</code></li>
<li>通过字典创建<ul>
<li>字典的key作为DataFrame的列索引</li>
</ul>
</li>
</ul>
<h4 id="索引和切片操作"><a href="#索引和切片操作" class="headerlink" title="索引和切片操作"></a>索引和切片操作</h4><h5 id="索引-1"><a href="#索引-1" class="headerlink" title="索引"></a>索引</h5><ul>
<li><code>df[&#39;col&#39;]</code>。取列</li>
<li><code>df.iloc[index]</code>。索引取行</li>
<li><code>df.iloc[index, col]</code>。索引取元素</li>
</ul>
<h5 id="切片-1"><a href="#切片-1" class="headerlink" title="切片"></a>切片</h5><ul>
<li><code>df[index1:index2]</code>。切行</li>
<li><code>df.iloc[:, col1 : col3]</code>。切列</li>
</ul>
<h4 id="时间序列的转换：从字符串object到datetime"><a href="#时间序列的转换：从字符串object到datetime" class="headerlink" title="时间序列的转换：从字符串object到datetime"></a>时间序列的转换：从字符串object到datetime</h4><p>注意DataFrame中所有的未表示为datetime的数据都应该将其转化为datetime类型以方便后续的进一步操作。</p>
<p><code>pd.to_datetime(df[col])</code></p>
<p>设置了datetime类型后，就可通过例如<code>df[&#39;date&#39;].dt.month</code>访问月份信息，同理可以访问如年份、日期等信息。</p>
<h4 id="设置行索引"><a href="#设置行索引" class="headerlink" title="设置行索引"></a>设置行索引</h4><p><code>df.set_index(col)</code>。将col列作为原始数据df的行索引</p>
<h4 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h4><p><code>df.to_xxx()</code>。<code>xxx</code>表示存储的文件类型。</p>
<h4 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h4><p><code>pd.read_xxx()</code>。可以将外部文件的数据读取加载到df</p>
<h4 id="对数据重新取样"><a href="#对数据重新取样" class="headerlink" title="对数据重新取样"></a>对数据重新取样</h4><p><code>df.resample(rule)</code>。对df的数据重新采样，rule就是取样的条件</p>
<h4 id="DataFrame中某一列纵向移动"><a href="#DataFrame中某一列纵向移动" class="headerlink" title="DataFrame中某一列纵向移动"></a>DataFrame中某一列纵向移动</h4><p><code>df[&#39;col&#39;].shift(1 or 1)</code>。将Series的元素整体上下移动1位。</p>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><h3 id="清洗空值（缺失值）"><a href="#清洗空值（缺失值）" class="headerlink" title="清洗空值（缺失值）"></a>清洗空值（缺失值）</h3><p>空值（丢失数据）有两种，分别是：</p>
<ul>
<li>None</li>
<li>np.nan</li>
</ul>
<p>2种丢失数据的区别</p>
<ul>
<li>数据分析中的np.nan是float类型，而None是对象类型</li>
<li>对象类型的空值不能直接参与运算，而nan可以直接参与运算</li>
</ul>
<h4 id="将空值对应行数据进行删除"><a href="#将空值对应行数据进行删除" class="headerlink" title="将空值对应行数据进行删除"></a>将空值对应行数据进行删除</h4><p><code>df.dropna()</code>。</p>
<h4 id="对空值进行填充"><a href="#对空值进行填充" class="headerlink" title="对空值进行填充"></a>对空值进行填充</h4><p><code>df.fillna()</code></p>
<p>常用的填充方式有以下3种</p>
<ul>
<li>近邻值填充<ul>
<li>例如<code>df.fillna(method = &#39;bfill&#39;, axis = 0)</code>表示用同一列的后一个数据填充</li>
</ul>
</li>
<li>均值，中位数填充<ul>
<li>需要使用循环和条件语句进行填充</li>
<li>需要注意的是，若Series中含有空值，则将其作为参数调用<code>np.median()</code>时必返回空</li>
</ul>
</li>
<li>任意值填充</li>
</ul>
<h3 id="清洗重复值"><a href="#清洗重复值" class="headerlink" title="清洗重复值"></a>清洗重复值</h3><p><code>df.drop_duplicated()</code></p>
<p>将重复的行数据进行删除。</p>
<h3 id="清洗异常值"><a href="#清洗异常值" class="headerlink" title="清洗异常值"></a>清洗异常值</h3><p>首先要有一个判定异常值的条件，根据条件再进行相关异常值的清洗操作。</p>
<h1 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h1><h2 id="pandas的高级用法"><a href="#pandas的高级用法" class="headerlink" title="pandas的高级用法"></a>pandas的高级用法</h2><h3 id="pandas级联操作"><a href="#pandas级联操作" class="headerlink" title="pandas级联操作"></a>pandas级联操作</h3><p>pandas使用<code>pd.concat()</code>函数，与<code>np.concatenate()</code>类似，但也有不同。不同之处在于不匹配级联的处理结果。</p>
<p>不匹配级联指的是级联维度的索引不一致，如纵向级联时列索引不一致，横向级联时行索引不一致。</p>
<p><code>pd.concat()</code>的连接方式有2种：</p>
<ul>
<li>外连接<code>outer</code>，类似于取并集，同时补空</li>
<li>内连接<code>inner</code>，类似取交集</li>
</ul>
<h3 id="pandas合并操作"><a href="#pandas合并操作" class="headerlink" title="pandas合并操作"></a>pandas合并操作</h3><p>级联是对表格进行简单的横/纵向拼接，而合并是对数据的合并。pandas的合并函数是<code>pd.merge()</code>。两者的区别在于merge需要提供某一共同列来进行合并。</p>
<p><code>pd.merge()</code>进行合并时，会自动根据两者相同<code>column</code>名称的那一列作为key进行合并。</p>
<h3 id="pandas替换操作"><a href="#pandas替换操作" class="headerlink" title="pandas替换操作"></a>pandas替换操作</h3><p>替换操作可以同步作用于Series和DataFrame中。</p>
<ul>
<li>单值替换<ul>
<li>普通替换：替换所有符合要求的元素。<code>df.replace(to_replace=old_value, value=new_value)</code></li>
<li>按列指定单值替换：<code>df.replace(to_replace={column_index : old_value}, value=new_value)</code></li>
</ul>
</li>
<li>多值替换<ul>
<li>列表替换：<code>df.replace(to_replace=[], value=[])</code></li>
<li>字典替换：<code>df.replace(to_replace={old_value : new_value, ...})</code></li>
</ul>
</li>
</ul>
<h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><p>通过创建一个映射关系列表，把values元素和一个特定的标签或者字符串绑定。</p>
<p>map是Series的方法，只能被Series调用。</p>
<p>可以向map中传入字典以建立这种联系。</p>
<h3 id="运算工具"><a href="#运算工具" class="headerlink" title="运算工具"></a>运算工具</h3><p>使用了函数式编程的思想，通过向Series的apply方法或map方法传入一个函数对Series的元素进行计算并将计算结果形成一个新的Series。</p>
<h3 id="随机抽样"><a href="#随机抽样" class="headerlink" title="随机抽样"></a>随机抽样</h3><p>DataFrame的take()方法可以实现DataFrame的重排，take()方法的两个重要参数分别是<code>indices</code>（隐式索引，标示新的排列顺序）和<code>axis</code>（重排的索引方向）。</p>
<p>为了实现随机重排，可以向<code>indices</code>传入<code>np.random.permutation()</code>。<code>np.random.permutation(n)</code>可以产生一个从0到n-1的随机排列。</p>
<h3 id="数据的分类处理"><a href="#数据的分类处理" class="headerlink" title="数据的分类处理"></a>数据的分类处理</h3><p>数据分类处理的核心函数是DataFrame的<code>groupby()</code>方法。</p>
<ul>
<li><code>df.groupby(by=column_index).groups</code>返回分组的情况。</li>
<li><code>df.groupby(by=column_index1)[column_index2]</code>返回一个<code>pandas.core.groupby.generic.SeriesGroupBy</code></li>
</ul>
<h3 id="高级数据聚合"><a href="#高级数据聚合" class="headerlink" title="高级数据聚合"></a>高级数据聚合</h3><p>使用了<code>groupby</code>分组后，可以使用<code>transform()</code>和<code>apply()</code>提供自定义的函数实现更多的运算。</p>
<p><code>apply()</code>和<code>transform()</code>的区别在于<code>transform()</code>返回的是经过了映射的结果。</p>
<h3 id="数据加载和分词"><a href="#数据加载和分词" class="headerlink" title="数据加载和分词"></a>数据加载和分词</h3><p>使用<code>pd.read_csv(filepath, sep, header)</code>可以实现更加细致的读取操作，其中：</p>
<ul>
<li><code>filepath</code>标识待读取的文件路径</li>
<li><code>sep</code>标识用于分词的符号，如常见的<code>-</code></li>
<li><code>header=None</code>将文件中的第一行也作为DataFrame中的数据而非列索引</li>
</ul>
<h3 id="读取数据库中的数据"><a href="#读取数据库中的数据" class="headerlink" title="读取数据库中的数据"></a>读取数据库中的数据</h3><p>这里以<code>sqlite3</code>包为例进行操作。</p>
<p>读取数据库首先应该获取连接对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">conn = sqlite3.connect(<span class="string">'./xxx.sqlite'</span>)  <span class="comment"># 建立数据库连接</span></span></pre></td></tr></table></figure>
<p>连接对象建立后，通过<code>pd.read_sql()</code>方法读取数据库中的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">sql_df = pd.read_sql(<span class="string">'select * from sheet'</span>, conn)</span></pre></td></tr></table></figure>
<p>向数据库中写入数据使用的是DataFrame的<code>to_sql()</code>方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">df.to_sql(<span class="string">'sheet_name'</span>, conn)</span></pre></td></tr></table></figure>
<h3 id="透视表"><a href="#透视表" class="headerlink" title="透视表"></a>透视表</h3><p>透视表是一种可以对数据动态排布并且进行分类汇总的表格格式。在pandas中使用DataFrame的<code>pivot_table()</code>方法创建。</p>
<p>透视表的优点有：</p>
<ul>
<li>灵活性高，可以随意定制分析需求</li>
<li>脉络清晰且易于理解</li>
<li>操作性强</li>
</ul>
<p>透视表<code>pivot_table</code>最重要的参数有4个，分别是：</p>
<ul>
<li><code>index</code>：分类的汇总条件。每个pivot_table必须有一个index</li>
<li><code>values</code>：对需要计算的数据进行筛选</li>
<li><code>columns</code>：对values字段进行分类</li>
<li><code>aggfunc</code>：设置我们对数据聚合时进行的函数操作</li>
</ul>
<h3 id="交叉表"><a href="#交叉表" class="headerlink" title="交叉表"></a>交叉表</h3><p>交叉表是一种用于计算分组的特殊透视图，用于对数据进行汇总。</p>
<p><code>pd.crosstab(index, columns)</code>，其中<code>index</code>为分组数据，是交叉表的行索引，<code>columns</code>是交叉表的列索引。</p>
<h1 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h1><h2 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h2><p>机器学习就是从数据中自动分析获得规律，并且利用这种规律对未知数据进行预测。</p>
<h3 id="算法模型"><a href="#算法模型" class="headerlink" title="算法模型"></a>算法模型</h3><p>机器学习中很重要的一点是建立和求解算法模型，算法模型是一个待解的数学模型。模型的训练过程可以看作用数据对模型进行求解。</p>
<p>算法模型的作用大致可以分为2种：</p>
<ul>
<li>对未知事物进行预测。预测是利用模型对一件事情计算出一个未知的结果</li>
<li>对未知事物进行分类。分类是讲一个未知类别的事物归到最合适的类别种</li>
</ul>
<h3 id="样本数据"><a href="#样本数据" class="headerlink" title="样本数据"></a>样本数据</h3><p>样本数据中值得关注的有2类，分别是：</p>
<ul>
<li>特征数据。可以看作是模型的自变量</li>
<li>标签/目标。可以看作是因变量</li>
</ul>
<h4 id="样本数据的载体"><a href="#样本数据的载体" class="headerlink" title="样本数据的载体"></a>样本数据的载体</h4><p>通常情况下历史数据都不会存储在数据库中，而是存储在文件中，例如<code>.csv</code>文件。</p>
<p>数据库存储数据存在以下几个问题：</p>
<ul>
<li>性能瓶颈：数据量极大的数据很难存储和进行高效的读写</li>
<li>数据格式不符合机器学习要求的格式</li>
</ul>
<h4 id="获取样本数据的常见途径"><a href="#获取样本数据的常见途径" class="headerlink" title="获取样本数据的常见途径"></a>获取样本数据的常见途径</h4><ul>
<li>kaggle数据竞赛平台</li>
<li>UCI数据集</li>
<li>sklearn</li>
</ul>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>特征工程主要包括以下步骤：</p>
<ul>
<li>特征抽取</li>
<li>数据特征的预处理</li>
<li>特征选择</li>
</ul>
<h3 id="为何需要特征工程？"><a href="#为何需要特征工程？" class="headerlink" title="为何需要特征工程？"></a>为何需要特征工程？</h3><p>样本数据可能存在种种问题不适合直接放入算法模型里参与运算或求解的效率不高。为此特征工程的目的就是为了构建一个更合适、更纯净的样本集，让基于这个数据集训练出来的模型具有更好的预测能力。</p>
<h3 id="特征工程的常用工具"><a href="#特征工程的常用工具" class="headerlink" title="特征工程的常用工具"></a>特征工程的常用工具</h3><p><code>sklearn</code>包。<code>sklearn</code>是python中的机器学习工具，包含了很多知名的机器学习算法的实现，包括常用的：</p>
<ul>
<li>分类模型</li>
<li>回归模型</li>
<li>聚类模型</li>
<li>特征工程</li>
</ul>
<h3 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h3><p>特征抽取的目的是讲样本中的不是数据形式的信息（如字符串等）转换成数值型的数据以便模型的计算。特征抽取的常见方法是特征值化，即讲非数值型的特征数据转换成数值形式的数据。</p>
<h4 id="字符串的特征值化"><a href="#字符串的特征值化" class="headerlink" title="字符串的特征值化"></a>字符串的特征值化</h4><p><code>sklearn.feature_extraction.text</code>包中的<code>CountVectorizer</code>类可以很直接的实现英文字符串的特征值化。向<code>CountVectorizer</code>类的<code>.fit_transform()</code>方法传入字符串的<code>list</code>，生成的结果是一个稀疏矩阵（sparse matrix），稀疏矩阵的结果不太直观，可以调用结果的<code>.toarray()</code>方法讲稀疏矩阵转为<code>list</code>。</p>
<p>中文的字符串不能直接使用这种方法进行特征值化。<code>CountVectorizer</code>类的分词基于英文的句子中的空格和标点符号等，但这种模式对中文分词显然不适用，为此，对于中文字符串，首先需要使用<code>jieba</code>包进行分词操作，讲分词后的结果用空格或标点符号进行分隔，这样再送入<code>CountVectorizer</code>类中进行处理。</p>
<h5 id="jieba"><a href="#jieba" class="headerlink" title="jieba"></a>jieba</h5><p>jieba包的<code>jieba.cut()</code>方法讲传入的字符串类型的中文字符串进行分词操作，返回一个对象，可以使用<code>list()</code>函数讲这个结果对象强转成list方便后续的操作。</p>
<p>分隔符的<code>.join()</code>方法可以将传入的list参数中的元素拼接成字符串。字符串拼接成功后就可以传入<code>CountVectorizer</code>进行类似英文字符串的处理。</p>
<h4 id="字典的特征值化"><a href="#字典的特征值化" class="headerlink" title="字典的特征值化"></a>字典的特征值化</h4><p><code>sklearn.feature_extraction</code>包中的<code>DictVectorizer</code>类可以对字典进行特征值化。向<code>DictVectorizer</code>的实例的<code>.fit_transform()</code>方法传入待特征值化的字典，方法返回一个稀疏矩阵。如果想得到list而非特殊矩阵，可以在<code>DictVectorizer</code>的构造函数中传入<code>sparse=False</code>参数。对<code>DictVectorizer</code>的实例调用<code>.get_feature_names()</code>可以得到类别的名称。</p>
<h4 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one hot编码"></a>one hot编码</h4><p>为了消除非数值数据的简单编号可能造成的权重偏差，需要对非数值数据进行one hot编码而非简单的数据编码。</p>
<p>pandas提供了<code>pd.get_dummies()</code>方法实现one hot编码。</p>
<h3 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h3><p>特征预处理中很重要的内容是<strong>无量纲化</strong>处理。</p>
<p>在机器学习算法实践中，往往需要将不同规格的数据转换到同一规格或不同分布的数据转换到某个特定分布需求。无量纲化处理可以提高模型求解速度，提示模型精度。不过决策树和树的集成算法则不需要无量纲化处理。</p>
<p>无量纲化处理的2个重要方式分别是：</p>
<ul>
<li>归一化</li>
<li>标准化</li>
</ul>
<h4 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h4><p>如果每个特征都有同样的权重，那么必须对其进行归一化处理。</p>
<p>归一化的公式为<script type="math/tex">X' = \frac{x-min}{max-min}</script> <script type="math/tex">X'' = X'\times(mx-mi)+mi</script></p>
<p>通常<code>mx = 1, mi = 0</code>。</p>
<p>归一化通过调用<code>sklearn.preprocessing</code>里的<code>MinMaxScaler</code>类实现归一化。<code>MinMaxScaler</code>的实例调用<code>.fit_transform()</code>方法对传入的特征矩阵参数进行归一化处理。</p>
<p>归一化的突出缺点在于：如果数据中存在的异常值较多，对最大值和最小值的影响很大，严重影响归一化的结果。</p>
<h4 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h4><p>概率论中有一种非常重要的分布——正态分布。如果能够在数据预处理阶段将数据处理成标准正态分布就再好不过了。</p>
<p>通过分析标准化的过程，即标准正态分布处理过程，不难发现异常值对标准化的影响不大。</p>
<p>标准化通过调用<code>sklearn.preprocessing</code>里的<code>StandardScaler</code>类进行标准化。<code>StandardScaler</code>类的实例调用<code>.fit_transform()</code>方法对传入的特征矩阵参数进行归一化处理。</p>
<h4 id="归一化-or-标准化？"><a href="#归一化-or-标准化？" class="headerlink" title="归一化 or 标准化？"></a>归一化 or 标准化？</h4><p>大多数机器学习算法需要标准化进行数据预处理，而归一化在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时被广泛使用，如数据图像中量化像素强度。</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>特征选择的第一步应该是与数据提供者联系，与相关业务人员交流，通过业务常识直接筛选特征。</p>
<p>特征选择能够精简特征的个数，取出相关度较高的冗余特征</p>
<p>通过常识进行第一步选择后，还可以通过数学方法进一步选择。</p>
<p>常用的方法有：</p>
<ul>
<li>filter过滤式</li>
<li>embedded嵌入式</li>
<li>PCA降维</li>
</ul>
<h4 id="filter过滤式"><a href="#filter过滤式" class="headerlink" title="filter过滤式"></a>filter过滤式</h4><p>过滤式通过特征数值的方差进行筛选。如果某个特征本身方差很小，就表示这个特征对于区分数据样本的作用非常有限，故应该首先过滤这种无用的特征。</p>
<p><code>sklearn.feature_selection</code>包中的<code>VarianceThreshold</code>类可以基于给定方差选择特征列，<code>VarianceThreshold</code>类的构造函数接收一个方差阈值，经过这个<code>VarianceThreshold</code>实例的<code>.fit_transform()</code>方法处理后的特征数据中只存在方差值大于或等于阈值的特征列。</p>
<h4 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h4><p>降维的维度值就是特征的种类。PCA可以削减回归分析或聚类分析中特征的数量。</p>
<p><code>sklearn.decomposition</code>包中的<code>PCA</code>类实例通过调用<code>.fit_transform()</code>方法对传入的数据进行PCA降维处理。</p>
<h1 id="Day-4"><a href="#Day-4" class="headerlink" title="Day 4"></a>Day 4</h1><h2 id="训练集、测试集划分"><a href="#训练集、测试集划分" class="headerlink" title="训练集、测试集划分"></a>训练集、测试集划分</h2><p>为了测试模型经过训练后在陌生数据上的表现能力，需要对原本的数据集进行划分，分成<strong>训练集</strong>和<strong>测试集</strong>。一般来说，数据集中80%作为训练集，20%作为测试集。</p>
<p><code>sklearn.model_selection</code>包提供<code>train_test_split()</code>函数进行训练集和测试集划分，如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">2020</span>)</span></pre></td></tr></table></figure>
<p>其中</p>
<ul>
<li><code>x_train</code>为函数返回的<strong>训练集特征</strong>数据</li>
<li><code>x_test</code>为函数返回的<strong>测试集特征</strong>数据</li>
<li><code>y_train</code>为函数返回的<strong>训练集标签</strong>数据</li>
<li><code>y_test</code>为函数返回的<strong>测试集标签</strong>数据</li>
<li><code>features</code>为待划分的<strong>特征</strong>数据</li>
<li><code>target</code>为待划分的<strong>标签</strong>数据</li>
<li><code>test_size=</code>传入测试集所占比例，例如取值<code>test_size=0.2</code>表示原数据集中20%划作测试集</li>
<li><code>random_state=</code>传入随机数种子，函数按照随机数种子生成的随机数随机划分原数据集</li>
</ul>
<h2 id="KNN分类算法"><a href="#KNN分类算法" class="headerlink" title="KNN分类算法"></a>KNN分类算法</h2><p>KNN方法是一个<strong>有监督的分类算法</strong>，采用不同特征值之间的距离方法进行分类。</p>
<p>KNN模型接受一个训练样本集，样本集中每个数据都存在标签。</p>
<p>输入新的无标签数据后，将新数据的每个特征与样本集中数据的每个特征进行比较，然后提取出样本集中特征最相似的数据的标签。</p>
<p>一般只选择K个最相似的数据，通常K不大于20。</p>
<p>最后这K个数据的分类标签中出现最多的标签被赋予新的数据，作为新数据的标签。</p>
<p><code>sklearn.neighbors</code>包中提供了<code>KNeighborsClassifier</code>类实现了KNN分类算法。类的实例接受参数K，使用<code>.fit()</code>方法训练模型。</p>
<p>使用KNN算法时，可以尝试对数据进行标准化以改善算法表现。</p>
<h2 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h2><p>算法模型中有一些参数是事先选取的，不依赖于特定的数据集，这些参数称为超参数。</p>
<p>超参数的变化会直接影响模型的表现。</p>
<p>为了寻找最佳的超参数取值，最简单的方法是对超参数进行枚举，并记录算法相应的表现，以此绘制学习曲线。</p>
<p>通过对KNN模型不同K值的结果分析不难得出：</p>
<ul>
<li>若K值较小，则模型容易发生过拟合，也就是预测结果对于邻近的数据点非常敏感</li>
<li>若K值较打，则模型的泛化能力相对较强，距离较远的数据点对预测结果也产生一定影响</li>
</ul>
<p>因此在应用中，K值一般取较小的值，并且采用下面的交叉验证法来选取最优的K值。</p>
<h2 id="K折交叉验证"><a href="#K折交叉验证" class="headerlink" title="K折交叉验证"></a>K折交叉验证</h2><p>K折交叉验证的目的是为了寻找最合适的超参数取值。</p>
<p>K折交叉验证将样本的数据集交叉的划分出不同的训练集和验证集，使用拆分后的不同的训练集和验证集分别测试模型的表现，并将表现取均值作为此次交叉验证的结果。对于不同的超参数都可以进行这样的交叉验证，由此选取合适的超参数。</p>
<p>K折交叉验证的大致过程如下：</p>
<ul>
<li>将原始数据划分出的<strong>训练集</strong>平分成K个等分</li>
<li>使用其中的1份作为<strong>验证集</strong>，其余作为<strong>训练集</strong></li>
<li>用此时的<strong>训练集</strong>训练模型，用<strong>验证集</strong>测试模型表现，记录此次表现结果</li>
<li>选取尚未选过的某一等份作为验证集，其余作为训练集，重复上一步，直到所有等分均被单独做过验证集</li>
<li>收集到的模型表现结果取均值，作为本次交叉验证的最后结果</li>
</ul>
<p><code>sklearn.model_selection</code>包提供<code>cross_val_score()</code>进行交叉验证，返回表现结果的均值。</p>
<p><code>cross_val_score()</code>接受3个参数：</p>
<ul>
<li><code>estimator=</code>模型对象</li>
<li><code>X=</code>待交叉验证划分的特征训练集</li>
<li><code>y=</code>待交叉验证划分的标签训练集</li>
<li><code>cv=</code>划分的折数K</li>
</ul>
<p>对KNN模型使用K折交叉验证如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, train_test_split</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># features是原始特征集，target是原始标签集</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">2020</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行5折交叉验证</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">cross_val_score(KNeighborsClassifier(n_neighbors=<span class="number">5</span>), x_train, y_train, cv=<span class="number">5</span>)</span></pre></td></tr></table></figure>
<h2 id="图片数据的等比例压缩和扁平化处理"><a href="#图片数据的等比例压缩和扁平化处理" class="headerlink" title="图片数据的等比例压缩和扁平化处理"></a>图片数据的等比例压缩和扁平化处理</h2><h3 id="等比例压缩"><a href="#等比例压缩" class="headerlink" title="等比例压缩"></a>等比例压缩</h3><p>假设目前图片的数据以<code>numpy.ndarray</code>的类型存储，而且它的大小不符合模型要求（如模型要求28<em>28而图片目前大小为130</em>105）。为了使之适应模型需要，需要调用<code>scipy.ndimage</code>包中的<code>ndimage</code>类的<code>zoom()</code>进行压缩处理。</p>
<p><code>ndimage.zoom()</code>函数需要2个参数：</p>
<ul>
<li>待处理图片array类型的数组</li>
<li><code>zoom=</code>接受一个tuple，(目标行大小/原始行大小, 目标列大小/原始列大小)</li>
</ul>
<h3 id="扁平化处理"><a href="#扁平化处理" class="headerlink" title="扁平化处理"></a>扁平化处理</h3><p>由于<code>sklearn</code>的模型在训练和预测时都需要传入二维数组，为此需要对图片进行相应扁平化处理，使得每一行表示一张图片。扁平化处理不需要额外函数，<code>numpy.ndarray</code>自带的<code>.reshape()</code>方法就可以实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># img_arr的大小是(28, 28)，为了符合模型要求，需要将其转化为(1, 28*28)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">img_arr.reshape((<span class="number">1</span>, <span class="number">784</span>))</span></pre></td></tr></table></figure>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>回归问题与分类问题不同，回归问题的目标值是连续性的。例如：</p>
<ul>
<li>房价预测问题</li>
<li>销售额预测问题</li>
</ul>
<p>值得注意的是，一组特征维度为n的特征集，经过回归处理后，数据集的权重系数会有n个。</p>
<p>标准的线性关系模型为：</p>
<script type="math/tex; mode=display">y = b + \sum_{i=1}^{n} w_i \times x_i</script><p>其中w称为权重，而b可以变换为$b = w_0 \times x_0, x_0 = 1$，那么模型可以简化为</p>
<script type="math/tex; mode=display">y = \sum_{i=0}^{n} w_i \times x_i</script><p>结合向量内积的定义，我们可以得出更一般的形式。</p>
<p>假设有m个样本，写成矩阵的形式就是：</p>
<script type="math/tex; mode=display">
\mathbf{X} = 
\begin{bmatrix}
  1 & x_1^1 & x_1^2 & ... & x_1^n \\\
  1 & x_2^1 & x_2^2 & ... & x_2^n \\\
  ... & ... & ... & ... & ... \\\
  1 & x_m^1 & x_m^2 & ... & x_m^n
\end{bmatrix}</script><script type="math/tex; mode=display">
\mathbf{y} = 
\begin{bmatrix}
  y_1 \\
  y_2 \\
  ... \\
  y_m
\end{bmatrix}</script><p>其中X为特征集，每列代表一个特征（除第1列），每行代表一个数据。Y为标签数据向量。</p>
<p>权重w也可以写成向量的形式：</p>
<script type="math/tex; mode=display">
\mathbf{w} = 
\begin{bmatrix}
  w_0 & w_1 & w_2 & ... & w_n
\end{bmatrix}</script><p>由此，线性模型的公式可以写为</p>
<script type="math/tex; mode=display">
\mathbf{y} = \mathbf{X}\mathbf{w}^{\mathrm{T}}</script><h3 id="减小误差的方法"><a href="#减小误差的方法" class="headerlink" title="减小误差的方法"></a>减小误差的方法</h3><p>回归算法是一个迭代算法，迭代是重复反馈过程的活动，目的通常是为了逼近所需目标或结果，每一次迭代得到的结果会作为下一次迭代的初始值。</p>
<p>回归算法就是在不断的自身迭代来减少误差以使得回归算法的预测结果可以越发的逼近真是结果。</p>
<p>为了通过迭代减少误差，首先需要定义误差的度量标准——损失函数：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^{m} (y_i - \textbf{X}_i \textbf{w})^2</script><p>由上述公式不难看出，误差的大小与线性回归方程中的系数w有直接关系，由此，问题转化成——如何求解方程中的w使得误差可以最小。</p>
<h3 id="L0，L1，L2范式"><a href="#L0，L1，L2范式" class="headerlink" title="L0，L1，L2范式"></a>L0，L1，L2范式</h3><ul>
<li>L0是向量中非0元素的个数</li>
<li>L1是向量中各个元素绝对值之和</li>
<li>L2是向量中各元素的平方和然后求平方根</li>
</ul>
<p>我们的损失函数代表了L2范式的平方结果， 因此我们的求解目标就转化成了</p>
<script type="math/tex; mode=display">
min_w || \mathbf{y} - \mathbf{X}\mathbf{w} ||_2^2</script><p>这个表达式一般称作SSE（误差平方和）或者RSS（残差平方和）。</p>
<h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>现在问题转化成了求解让RSS最小化的参数向量w，这种方法称为最小二乘法。</p>
<p>通过最小二乘法计算出的w表达式为：</p>
<script type="math/tex; mode=display">
\mathbf{w} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^{\mathrm{T}} \mathbf{y}</script><p><code>sklearn.linear_model</code>包中<code>LinearRegression</code>类可以提供一个线性回归的模型实例，实例使用<code>.fit()</code>方法进行训练。</p>
<p>需要注意的是回归问题中一般不需要进行无量纲化。</p>
<h2 id="回归算法的评价"><a href="#回归算法的评价" class="headerlink" title="回归算法的评价"></a>回归算法的评价</h2><p>回归算法的评价指标可以从2个角度来看待回归的结果：</p>
<ul>
<li>是否预测到了正确或者接近正确的数值</li>
<li>是否拟合到了足够的信息</li>
</ul>
<p>以上2种角度，分别对应着不同的模型评估指标。</p>
<h3 id="是否预测到了正确或者接近正确的数值"><a href="#是否预测到了正确或者接近正确的数值" class="headerlink" title="是否预测到了正确或者接近正确的数值"></a>是否预测到了正确或者接近正确的数值</h3><p>首先考虑残差平方和RSS是否是一个合适的指标。RSS反映了预测值与真实值之间的偏差，但是它是一个无界的和，可以无限大或无限小。所以<code>sklearn</code>使用RSS的变体均方误差（mean squared error）衡量预测值和真实值的差异。</p>
<script type="math/tex; mode=display">
MSE = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2</script><p>不难看出均方误差是每个样本量上的平均误差。有了这个平均误差，就可以将其与标签的取值范围一起比较，以此获得一个较为可靠的评估依据。</p>
<p>在<code>sklearn</code>中有2种常见的函数使用了这个评估方式：</p>
<ul>
<li><code>sklearn.metrics</code>包中提供了<code>mean_squared_error</code>类</li>
<li>交叉验证的类<code>cross_val_score</code>向参数<code>scoring</code>赋值<code>neg_mean_squared_error</code></li>
</ul>
<h3 id="是否拟合到了足够的信息"><a href="#是否拟合到了足够的信息" class="headerlink" title="是否拟合到了足够的信息"></a>是否拟合到了足够的信息</h3><p>对于回归类算法而言，仅探索数据预测是否准确是不足够的。除了数据本身的数值大小外，我们还希望模型能够捕捉到数据的规律，而这是无法用MSE衡量的。</p>
<p>回忆在特征工程中的特征选择环节中我们曾经根据方差来衡量数据的信息量。如果方差越大代表数据的信息量越大，这个信息量中不仅包含了数值本身的大小，还包含了我们希望模型捕捉到的那些规律。为此，我们定义了一种新的指标：</p>
<script type="math/tex; mode=display">
R^2 = 1 - \frac{RSS}{\sum_{i=0}^{m} (y_i-\bar{y})^2}</script><p>$R^2$的分子表示的是真实值和预测值之间的差值，也就是我们的模型未能捕捉到的信息量，而分母是真实标签所带的信息量，所以其衡量的是</p>
<script type="math/tex; mode=display">
1 - \frac{模型未捕获的信息量}{真实标签中所带的信息量}</script><p>这个指标越接近1越好。</p>
<p><code>sklearn</code>中有常见的以下3种方式调用这个指标：</p>
<ul>
<li><code>sklearn.metrics</code>包中有<code>r2_score</code>类</li>
<li><code>LinearRegression</code>类中的<code>score</code></li>
<li>在交叉验证中输入<code>r2</code></li>
</ul>
<h1 id="Day-5"><a href="#Day-5" class="headerlink" title="Day 5"></a>Day 5</h1><h2 id="欠拟合-amp-过拟合"><a href="#欠拟合-amp-过拟合" class="headerlink" title="欠拟合 &amp; 过拟合"></a>欠拟合 &amp; 过拟合</h2><h3 id="欠拟合"><a href="#欠拟合" class="headerlink" title="欠拟合"></a>欠拟合</h3><p>一个模型在训练数据上不能获得很好的拟合结果，但在训练数据之外的数据集上也不能很好的拟合数据，则我们认为这个模型出现了欠拟合现象。（如模型过于简单）</p>
<p>欠拟合常用的解决方法是增加样本的特征数量，如采用多项式回归。</p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>一个模型在训练数据上能够获得非常好的拟合，但是在训练数据以外的数据集上却不能很好的拟合数据，则我们认为这个模型出现了过拟合现象。（如模型过于复杂）</p>
<p>过拟合的解决方法有：</p>
<ul>
<li>进行特征选择，消除关联性大的特征</li>
<li>正则化之岭回归</li>
</ul>
<h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p>线性回归模型有个很明显的缺点——回归出的是线性模型，但是数据的规律更多的有可能是非线性的。线性模型无法捕捉到特征与目标之间的非线性关系，因此表现往往不佳。</p>
<p>为了解决这个问题，经常需要使用高次多项式建立模型拟合曲线。次数过高会导致过拟合，次数不够则会导致欠拟合。</p>
<p>如二次多项式函数：</p>
<script type="math/tex; mode=display">
y = \sum_{i=0}^{n} w_i x^i</script><p>实际上，多项式回归可以看作特殊的线性模型，即把高次项看作新的特征，这样形式上又回到了线性回归的模型。</p>
<p>多项式回归的最高次选择取决于样本本身，需要选择一个合适的最高次项，如果选择的次数过高，则会导致过拟合，次数过低又会导致欠拟合。</p>
<p><code>sklearn.preprocessing</code>包中提供了<code>PolynomialFeatures</code>类来构造更高次的特征。它是用多项式的方法来进行的，如有a，b两个特征，那么它们的2次多项式为$(1, a, b, a^2, ab, b^2)$</p>
<p><code>PolynomialFeatures</code>中最重要的参数<code>degree=</code>用来控制多项式的度。</p>
<h2 id="过拟合处理：正则化"><a href="#过拟合处理：正则化" class="headerlink" title="过拟合处理：正则化"></a>过拟合处理：正则化</h2><p>将过拟合的凹凸幅度减小可以将过拟合曲线趋近于拟合的曲线，而凹凸程度主要是由高次项导致的，那么正则化就是调小高次项的权重以解决过拟合的问题。</p>
<p><code>LinearRegression</code>类无法进行正则化，所以这个模型可能导致过拟合且其不提供解决方法。</p>
<h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>正则化的回归模型（Ridge岭回归）使用L2正则化处理过拟合问题。</p>
<p><code>sklearn.linear_model</code>包中<code>Ridge</code>类提供了岭回归模型，传入的参数主要有<code>alpha=</code>，用于指示正则化的力度，力度越大，表示高次项的权重越接近于0。</p>
<h2 id="模型的保存和加载"><a href="#模型的保存和加载" class="headerlink" title="模型的保存和加载"></a>模型的保存和加载</h2><p><code>sklearn.externals</code>包中提供了<code>joblib</code>用于保存和加载模型。</p>
<ul>
<li><code>joblib.dump(model, &#39;name.m&#39;)</code>用于保存模型</li>
<li><code>joblib.load(&#39;name.m&#39;)</code>用于加载模型</li>
</ul>
<p><code>pickle</code>包中也提供了模型保存和加载的方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型保存</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'./name.pkl'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">  pickle.dump(model, fp)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型加载</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'./name.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> fp:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">  pickle.load(fp)</span></pre></td></tr></table></figure>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>在许多分类算法的应用中，特征和标签之间的关系并非是决定性的。因此，我们希望算法得出的结论并非确定性的结论，而是结果的可能性概率。比如文章分类模型，我们希望模型能够返回某文章属于各个类别的概率。</p>
<p>朴素贝叶斯正是这样的一种算法，它直接衡量标签和特征之间的概率关系的有监督学习算法，是一种专注分类的算法。朴素贝叶斯基于概率论和数理统计的“贝叶斯推断”。</p>
<h3 id="贝叶斯推断"><a href="#贝叶斯推断" class="headerlink" title="贝叶斯推断"></a>贝叶斯推断</h3><p>贝叶斯推断是一种统计学方法，用来估计统计量的某种性质，是贝叶斯定理的应用。</p>
<p>要理解贝叶斯推断，首先要理解贝叶斯定理</p>
<h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><p>贝叶斯定理中非常重要的2个概念是<strong>先验概率</strong>和<strong>后验概率</strong>。</p>
<p>假设这样一个情景，出门堵车的原因有2个：</p>
<ul>
<li>车辆太多</li>
<li>交通事故</li>
</ul>
<p>先验概率就是堵车的概率（不管原因），可以将其看作是结果发生的概率$P(结果)$。</p>
<p>后验概率则是“由果推因”，即$P(原因_i|结果)$</p>
<p>贝叶斯定理里特指的条件概率则是由因推果，即$P(结果|原因_i)$</p>
<p>问题在于后验概率通常难以计算，但是通过贝叶斯公式，我们可以用先验概率、条件概率等计算后验概率，即</p>
<script type="math/tex; mode=display">
P(原因_i|结果) = \frac{P(原因_i, 结果)}{P(结果)} = \frac{P(结果|原因_i) P(原因_i)}{P(结果)}</script><p>朴素贝叶斯只适用于特征之间条件独立的情况下，否则分类效果不好。这里的“朴素”指的就是条件独立。</p>
<p>朴素贝叶斯主要被广泛地用于文档分类中。</p>
<h3 id="朴素贝叶斯的分类"><a href="#朴素贝叶斯的分类" class="headerlink" title="朴素贝叶斯的分类"></a>朴素贝叶斯的分类</h3><p><code>sklearn</code>提供了3种不同类型的贝叶斯模型算法：</p>
<ul>
<li>高斯模型</li>
<li>多项式模型</li>
<li>伯努利模型</li>
</ul>
<h4 id="高斯模型"><a href="#高斯模型" class="headerlink" title="高斯模型"></a>高斯模型</h4><p>通过假设$P(x_i|Y)$服从高斯分布来估计训练集数据的每个样本特征分到类别Y的条件概率。</p>
<p><code>sklearn.naive_bayes</code>包中提供了<code>GaussianNB</code>类作为高斯模型的实现。</p>
<p>实例化<code>GaussianNB</code>类时不需要输入任何参数，非常轻量，但这也意味着贝叶斯没有太多的参数可以调整，因此贝叶斯算法的成长空间并不是太大，如果贝叶斯算法的效果不太理想，我们一般会考虑换模型。</p>
<p><code>GaussianNB</code>的实例提供了2个方法返回模型计算的概率值：</p>
<ul>
<li><code>.predict_proba()</code>给出每个测试集样本属于每个类别的概率，最大的就是分类结果。</li>
<li><code>.predict_log_proba()</code>对<code>.predict_proba()</code>的对数转化，最大的就是分类结果。</li>
</ul>
<h4 id="多项式模型"><a href="#多项式模型" class="headerlink" title="多项式模型"></a>多项式模型</h4><p>与高斯分布不同，多项式模型主要适用于离散特征的概率计算，需要处理连续性变量时最好采用高斯模型。</p>
<p>值得注意的是，<code>sklearn</code>的多项式模型不接受负值输入，所以样本数据如出现负值，要进行归一化处理。</p>
<p>以文章类别分类为例，给定一篇文章，模型需要计算它属于各种类别的概率，也就是$P(类别|文章)$，而文章可以看作词语组成的序列，那么</p>
<script type="math/tex; mode=display">
P(类别|文章) = P(类别|词_1, 词_2, ..., 词_n) \\
= \frac{P(词_1, 词_2, ..., 词_n|类别) P(类别)}{P(词_1, 词_2, ..., 词_n)} \\
= \frac{P(词_1|类别)P(词_2|类别) ... P(词_n|类别)P(类别)}{P(词_1, 词_2, ..., 词_n)}</script><p>上述公式有个问题，若训练数据中某类别下某词的出现概率为0，则经过该模型计算后含有该词的某文章属于该类别的概率就是0，这肯定是不合适的，因为仅仅一个词就使得某文章属于某类别的概率直接为0，所以在这种情况下需要进行<strong>拉普拉斯平滑</strong>处理。</p>
<script type="math/tex; mode=display">
P(F1|C) = \frac{Ni+\alpha}{N+\alpha m}</script><p>$\alpha$为指定的系数，一般为1，m为训练文档中统计出的特征词个数。</p>
<p><code>sklearn.naive_bayes</code>提供了<code>MultinomialNB</code>类实现多项式模型，该类的实例中<code>alpha=</code>参数用于指定拉普拉斯平滑系数。</p>
<h4 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h4><p>在文本处理和信息检索中，TF-IDF是一种统计方法，用以评估一个单词在一个文档集合或语料库中的重要程度。</p>
<p>TF-IDF实际上是TF*IDF，主要思想是：如果某个词或短语在一篇文章中出现的频率高（即TF高），且在其他文章中很少出现（即IDF高），那么可以认为这个词或短语具有很好的类别区分能力，适合用作分类。</p>
<p>其中，</p>
<script type="math/tex; mode=display">
TF(某词) = \frac{该词在文档中出现的次数}{文档的总词数}</script><p><code>sklearn.feature_extraction.text</code>包提供<code>TfidfVectorizer</code>类求TF-IDF值。使用该类实例的<code>.fit_transform()</code>方法对原特征集进行处理，得出新的特征集。</p>
<h4 id="伯努利模型"><a href="#伯努利模型" class="headerlink" title="伯努利模型"></a>伯努利模型</h4><p>伯努利模型与多项式模型非常相似，都用于处理文本分类数据，但由于伯努利处理的是二项分布，所以它更在意“是或否”。伯努利模型每个特征的取值只能是0或1，所以它比<code>MultinomailNB</code>多定义一个二值化方法，该方法接受一个阈值并将输入的特征二值化（0或1）</p>
<p><code>sklearn.naive_bayes</code>包中的<code>BernoulliNB</code>类提供了伯努利模型。该类的实例同样接受一个拉普拉斯平滑系数，同时它还接受一个<code>binarize=</code>参数，可以是数值或不输入，不输入表示特征以全部二值化；输入数值则表示小于等于该值的归为一类，大于的归为另一类。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/09/01/CSAPP-datalab/" rel="prev" title="CSAPP-datalab">
      <i class="fa fa-chevron-left"></i> CSAPP-datalab
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Day-1"><span class="nav-number">2.</span> <span class="nav-text">Day 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#numpy"><span class="nav-number">2.1.</span> <span class="nav-text">numpy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy数组和列表的区别"><span class="nav-number">2.1.1.</span> <span class="nav-text">numpy数组和列表的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy数组常见的创建方式"><span class="nav-number">2.1.2.</span> <span class="nav-text">numpy数组常见的创建方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#numpy的常用属性"><span class="nav-number">2.1.3.</span> <span class="nav-text">numpy的常用属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数组的索引和切片方式"><span class="nav-number">2.1.4.</span> <span class="nav-text">数组的索引和切片方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#索引"><span class="nav-number">2.1.4.1.</span> <span class="nav-text">索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切片"><span class="nav-number">2.1.4.2.</span> <span class="nav-text">切片</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#变形"><span class="nav-number">2.1.5.</span> <span class="nav-text">变形</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#级联"><span class="nav-number">2.1.6.</span> <span class="nav-text">级联</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一些常用的数值方法"><span class="nav-number">2.1.7.</span> <span class="nav-text">一些常用的数值方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于矩阵"><span class="nav-number">2.1.8.</span> <span class="nav-text">基于矩阵</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pandas"><span class="nav-number">2.2.</span> <span class="nav-text">pandas</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Series"><span class="nav-number">2.2.1.</span> <span class="nav-text">Series</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建方法"><span class="nav-number">2.2.2.</span> <span class="nav-text">创建方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#重要方法"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">重要方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DataFrame"><span class="nav-number">2.2.3.</span> <span class="nav-text">DataFrame</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建方式"><span class="nav-number">2.2.3.1.</span> <span class="nav-text">创建方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#索引和切片操作"><span class="nav-number">2.2.3.2.</span> <span class="nav-text">索引和切片操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#索引-1"><span class="nav-number">2.2.3.2.1.</span> <span class="nav-text">索引</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#切片-1"><span class="nav-number">2.2.3.2.2.</span> <span class="nav-text">切片</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#时间序列的转换：从字符串object到datetime"><span class="nav-number">2.2.3.3.</span> <span class="nav-text">时间序列的转换：从字符串object到datetime</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置行索引"><span class="nav-number">2.2.3.4.</span> <span class="nav-text">设置行索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#持久化存储"><span class="nav-number">2.2.3.5.</span> <span class="nav-text">持久化存储</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#加载数据"><span class="nav-number">2.2.3.6.</span> <span class="nav-text">加载数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对数据重新取样"><span class="nav-number">2.2.3.7.</span> <span class="nav-text">对数据重新取样</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DataFrame中某一列纵向移动"><span class="nav-number">2.2.3.8.</span> <span class="nav-text">DataFrame中某一列纵向移动</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据清洗"><span class="nav-number">2.3.</span> <span class="nav-text">数据清洗</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#清洗空值（缺失值）"><span class="nav-number">2.3.1.</span> <span class="nav-text">清洗空值（缺失值）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#将空值对应行数据进行删除"><span class="nav-number">2.3.1.1.</span> <span class="nav-text">将空值对应行数据进行删除</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对空值进行填充"><span class="nav-number">2.3.1.2.</span> <span class="nav-text">对空值进行填充</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#清洗重复值"><span class="nav-number">2.3.2.</span> <span class="nav-text">清洗重复值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#清洗异常值"><span class="nav-number">2.3.3.</span> <span class="nav-text">清洗异常值</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Day-2"><span class="nav-number">3.</span> <span class="nav-text">Day 2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pandas的高级用法"><span class="nav-number">3.1.</span> <span class="nav-text">pandas的高级用法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pandas级联操作"><span class="nav-number">3.1.1.</span> <span class="nav-text">pandas级联操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pandas合并操作"><span class="nav-number">3.1.2.</span> <span class="nav-text">pandas合并操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pandas替换操作"><span class="nav-number">3.1.3.</span> <span class="nav-text">pandas替换操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#映射"><span class="nav-number">3.1.4.</span> <span class="nav-text">映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#运算工具"><span class="nav-number">3.1.5.</span> <span class="nav-text">运算工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机抽样"><span class="nav-number">3.1.6.</span> <span class="nav-text">随机抽样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据的分类处理"><span class="nav-number">3.1.7.</span> <span class="nav-text">数据的分类处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高级数据聚合"><span class="nav-number">3.1.8.</span> <span class="nav-text">高级数据聚合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据加载和分词"><span class="nav-number">3.1.9.</span> <span class="nav-text">数据加载和分词</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#读取数据库中的数据"><span class="nav-number">3.1.10.</span> <span class="nav-text">读取数据库中的数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#透视表"><span class="nav-number">3.1.11.</span> <span class="nav-text">透视表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉表"><span class="nav-number">3.1.12.</span> <span class="nav-text">交叉表</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Day-3"><span class="nav-number">4.</span> <span class="nav-text">Day 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习简介"><span class="nav-number">4.1.</span> <span class="nav-text">机器学习简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#算法模型"><span class="nav-number">4.1.1.</span> <span class="nav-text">算法模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#样本数据"><span class="nav-number">4.1.2.</span> <span class="nav-text">样本数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#样本数据的载体"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">样本数据的载体</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#获取样本数据的常见途径"><span class="nav-number">4.1.2.2.</span> <span class="nav-text">获取样本数据的常见途径</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征工程"><span class="nav-number">4.2.</span> <span class="nav-text">特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为何需要特征工程？"><span class="nav-number">4.2.1.</span> <span class="nav-text">为何需要特征工程？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征工程的常用工具"><span class="nav-number">4.2.2.</span> <span class="nav-text">特征工程的常用工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征抽取"><span class="nav-number">4.2.3.</span> <span class="nav-text">特征抽取</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#字符串的特征值化"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">字符串的特征值化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#jieba"><span class="nav-number">4.2.3.1.1.</span> <span class="nav-text">jieba</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#字典的特征值化"><span class="nav-number">4.2.3.2.</span> <span class="nav-text">字典的特征值化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#one-hot编码"><span class="nav-number">4.2.3.3.</span> <span class="nav-text">one hot编码</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征预处理"><span class="nav-number">4.2.4.</span> <span class="nav-text">特征预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#归一化"><span class="nav-number">4.2.4.1.</span> <span class="nav-text">归一化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#标准化"><span class="nav-number">4.2.4.2.</span> <span class="nav-text">标准化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#归一化-or-标准化？"><span class="nav-number">4.2.4.3.</span> <span class="nav-text">归一化 or 标准化？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征选择"><span class="nav-number">4.2.5.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#filter过滤式"><span class="nav-number">4.2.5.1.</span> <span class="nav-text">filter过滤式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PCA降维"><span class="nav-number">4.2.5.2.</span> <span class="nav-text">PCA降维</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Day-4"><span class="nav-number">5.</span> <span class="nav-text">Day 4</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#训练集、测试集划分"><span class="nav-number">5.1.</span> <span class="nav-text">训练集、测试集划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN分类算法"><span class="nav-number">5.2.</span> <span class="nav-text">KNN分类算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#超参数"><span class="nav-number">5.3.</span> <span class="nav-text">超参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K折交叉验证"><span class="nav-number">5.4.</span> <span class="nav-text">K折交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图片数据的等比例压缩和扁平化处理"><span class="nav-number">5.5.</span> <span class="nav-text">图片数据的等比例压缩和扁平化处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#等比例压缩"><span class="nav-number">5.5.1.</span> <span class="nav-text">等比例压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#扁平化处理"><span class="nav-number">5.5.2.</span> <span class="nav-text">扁平化处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归"><span class="nav-number">5.6.</span> <span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#减小误差的方法"><span class="nav-number">5.6.1.</span> <span class="nav-text">减小误差的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L0，L1，L2范式"><span class="nav-number">5.6.2.</span> <span class="nav-text">L0，L1，L2范式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最小二乘法"><span class="nav-number">5.6.3.</span> <span class="nav-text">最小二乘法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#回归算法的评价"><span class="nav-number">5.7.</span> <span class="nav-text">回归算法的评价</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#是否预测到了正确或者接近正确的数值"><span class="nav-number">5.7.1.</span> <span class="nav-text">是否预测到了正确或者接近正确的数值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#是否拟合到了足够的信息"><span class="nav-number">5.7.2.</span> <span class="nav-text">是否拟合到了足够的信息</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Day-5"><span class="nav-number">6.</span> <span class="nav-text">Day 5</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#欠拟合-amp-过拟合"><span class="nav-number">6.1.</span> <span class="nav-text">欠拟合 &amp; 过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#欠拟合"><span class="nav-number">6.1.1.</span> <span class="nav-text">欠拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过拟合"><span class="nav-number">6.1.2.</span> <span class="nav-text">过拟合</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多项式回归"><span class="nav-number">6.2.</span> <span class="nav-text">多项式回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#过拟合处理：正则化"><span class="nav-number">6.3.</span> <span class="nav-text">过拟合处理：正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L2正则化"><span class="nav-number">6.3.1.</span> <span class="nav-text">L2正则化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型的保存和加载"><span class="nav-number">6.4.</span> <span class="nav-text">模型的保存和加载</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯"><span class="nav-number">6.5.</span> <span class="nav-text">朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#贝叶斯推断"><span class="nav-number">6.5.1.</span> <span class="nav-text">贝叶斯推断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贝叶斯定理"><span class="nav-number">6.5.2.</span> <span class="nav-text">贝叶斯定理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#朴素贝叶斯的分类"><span class="nav-number">6.5.3.</span> <span class="nav-text">朴素贝叶斯的分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#高斯模型"><span class="nav-number">6.5.3.1.</span> <span class="nav-text">高斯模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多项式模型"><span class="nav-number">6.5.3.2.</span> <span class="nav-text">多项式模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TF-IDF"><span class="nav-number">6.5.3.3.</span> <span class="nav-text">TF-IDF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#伯努利模型"><span class="nav-number">6.5.3.4.</span> <span class="nav-text">伯努利模型</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jared Shaw</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jared Shaw</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.5.0
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
